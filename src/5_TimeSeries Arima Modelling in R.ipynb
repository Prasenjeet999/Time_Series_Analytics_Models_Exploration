{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tseries)\n",
    "library(tsibble)\n",
    "library(forecast)\n",
    "\n",
    "library(stats)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(corrplot)\n",
    "library(broom)\n",
    "library(ggpubr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f4dca",
   "metadata": {},
   "source": [
    "### Load the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d62b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "df = read.csv(\"data/Preprocessed_Dataset.csv\", sep = \",\")\n",
    "df$Date <- as.Date(df$Date, format = \"%Y-%m-%d\")\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92f5be",
   "metadata": {},
   "source": [
    "**Time Series Analysis (ARIMA Modeling) Assessing** the behavior/data-generating process of the time-series To understand the data-generating process in an overview, we can find correlations among different lags, before jumping further.\n",
    "\n",
    "We have done analysis on the top selling Walmart store in US.\n",
    "\n",
    "Selecting the top Walmart with best sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac859b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20 <- df[df$Store == '20', ]\n",
    "rownames(df_20) <- NULL\n",
    "df_20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3de41",
   "metadata": {},
   "source": [
    "### What is Stationary in Time Series Context?\n",
    "\n",
    "In time series analysis, a time series is said to be stationary if its statistical properties remain constant over time. More formally, a time series is stationary if its mean, variance, and covariance are all constant over time.\n",
    "\n",
    "The reason we need to check for stationarity is that many time series models, such as ARIMA and SARIMA, assume that the time series is stationary. If the time series is not stationary, these models may produce incorrect or unreliable forecasts. Additionally, non-stationary time series may exhibit trends or seasonal patterns that can make it difficult to discern underlying patterns and relationships in the data. By checking for stationarity and transforming the data if necessary, we can make the time series more amenable to analysis and modeling.\n",
    "\n",
    "\n",
    "### Tests to validate Stationary:\n",
    "\n",
    "Augmented Dickey-Fuller (ADF) test and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test are statistical tests used to check whether a time series is stationary or not.\n",
    "\n",
    "1. The ADF test is a hypothesis test that checks whether a time series has a unit root, which is a characteristic of non-stationarity. The null hypothesis of the test is that the time series has a unit root, while the alternative hypothesis is that it does not. If the test rejects the null hypothesis, it provides evidence that the time series is stationary.\n",
    "\n",
    "2. The KPSS test is also a hypothesis test that checks for stationarity, but it takes a slightly different approach than the ADF test. The KPSS test checks whether the time series can be represented as a stationary process around a deterministic trend. The null hypothesis of the test is that the time series is stationary, while the alternative hypothesis is that it has a unit root and is non-stationary. If the test rejects the null hypothesis, it provides evidence that the time series is non-stationary.\n",
    "\n",
    "In summary, both the ADF and KPSS tests are used to check whether a time series is stationary or not. The ADF test checks for a unit root in the time series, while the KPSS test checks for stationarity around a deterministic trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b48fa",
   "metadata": {},
   "source": [
    "**1. ADF TEST:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ADF test on \"Weekly_Sales\"\n",
    "adf_result <- adf.test(df_20$Weekly_Sales)\n",
    "adf_result\n",
    "\n",
    "# Print the test results\n",
    "cat(\"ADF test p-value:\", adf_result$p.value)\n",
    "if (adf_result$p.value < 0.05) {\n",
    "  cat(\"\\nThe time series is stationary at the 5% significance level.\")\n",
    "} else {\n",
    "  cat(\"\\nThe time series is not stationary at the 5% significance level.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373c18a",
   "metadata": {},
   "source": [
    "**2. KPSS Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b54965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KPSS test on \"Weekly_Sales\"\n",
    "kpss_result <- kpss.test(df_20$Weekly_Sales)\n",
    "kpss_result\n",
    "\n",
    "# Print the test results\n",
    "cat(\"KPSS test p-value:\", kpss_result$p.value)\n",
    "if (kpss_result$p.value < 0.05) {\n",
    "  cat(\"\\nThe time series is not stationary at the 5% significance level.\")\n",
    "} else {\n",
    "  cat(\"\\nThe time series is stationary at the 5% significance level.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa646d5",
   "metadata": {},
   "source": [
    "The ADF and KPSS Tests Suggests that the Data is now stationary.\n",
    "\n",
    "### Creating ts(Time Series) and tsibble Objects\n",
    "\n",
    "To conduct the analysis, the data needs to be in ts format. To do this, we set the frequency to the number of weeks in a year (365/7), so a period represents a week. Furthermore, we subset all expect the date column and set the start date to the sixth period of 2010. The week number of the first date in the time series is actually 5, but after inspection, setting the start date to the sixth week created the correct ts and tsibble objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"The length of the time series is\", nrow(df_20), \"weeks and it ranges from\", min(df_20$Date), \"to\", max(df_20$Date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99f8a6",
   "metadata": {},
   "source": [
    "Creating Time Series data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts <- ts(df_20[, 2:ncol(df_20)], start = c(2010, 6),  frequency = 365.25 / 7)\n",
    "str(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facc4b2",
   "metadata": {},
   "source": [
    "Creating a tsibble object from the ts object and print its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsbl <- as_tsibble(ts, pivot_longer = FALSE)\n",
    "str(tsbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b894b5",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Mid- to long-term projections are perhaps more significant than short-term forecasts because the goal is to predict the weekly sales of a Walmart store. In a week, a month, or even a few months, it's unlikely that the Walmart shop will be able to make many changes to its offerings or store. To respond to a specific forecast in the present, the store may need to undergo significant modifications over a period of several months. The store may need to do renovations, hire new staff, or look for new vendors. When large sales are anticipated, Walmart might even choose to pursue a new market opportunity like expanding the branch. As a result, a forecast horizon of a year, or around 52 weeks, appears to be appropriate. Week 43 of 2012 is the final week of the times series. So the forecasting inquiry is: How can we anticipate weekly sales to vary between week 43 of 2012 and week 43 of 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f0b35",
   "metadata": {},
   "source": [
    "### 1. Arima Modelling:\n",
    "\n",
    "A different method for forecasting time series is offered by ARIMA models. The two most popular methods for predicting time series are exponential smoothing and ARIMA models, both of which offer complementary approaches to the issue. While ARIMA models seek to describe the autocorrelations in the data, exponential smoothing models are based on a description of the trend and seasonality in the data.\n",
    "\n",
    "Arima modelling has three main parameters: \n",
    "1. The autoregressive (AR) terms capture the effect of the past values of the series on its current value.\n",
    "2. The moving average (MA) terms capture the effect of the past errors (residuals) on the current value of the series. \n",
    "3. The integrated (I) term indicates the number of times the series needs to be differenced in order to achieve stationarity.\n",
    "\n",
    "So for example, in ARIMA modeling, (3,0,1) represents the order of the model. Specifically, it indicates that the model includes 3 autoregressive (AR) terms, 0 integrated (I) terms, and 1 moving average (MA) term.\n",
    "\n",
    "**Checking the AIC and BIC values for choosing the best parameters for Arima:**\n",
    "\n",
    "For the choosing parameter, we choose the model with the lowest AIC and BIC values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC(\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,0)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,1)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,2)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,3)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,0)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,1)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,2)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,3))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d546c",
   "metadata": {},
   "source": [
    "Based on the AIC values, the best suggested ARIMA is ARIMA(3,0,3) or ARIMA(3,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ce773",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC(\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,0)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,1)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,2)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(4,0,3)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,0)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,1)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,2)),\n",
    "  arima(tsbl$Weekly_Sales,order=c(3,0,3))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2461a2",
   "metadata": {},
   "source": [
    "Based on the BIC values, the best suggested ARIMA is ARIMA(3,0,3) or ARIMA(4,0,2)\n",
    "\n",
    "One can also use auto.arima to get the ARIMA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 <- auto.arima(tsbl$Weekly_Sales,stationary=FALSE,allowdrift=FALSE, seasonal=FALSE,stepwise=FALSE,approximation=FALSE)\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8dc602",
   "metadata": {},
   "source": [
    "From auto.arima, we see that the best parameters are (0,0,4) which is different from the parameters we choose by AIC and BIC technique.\n",
    "\n",
    "Plotting the residuals for model 1 to see whether they are white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdisplay(residuals(model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef52b68",
   "metadata": {},
   "source": [
    "From the ACF and PACF plots, suggests it is not white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33433ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arima\n",
    "arima_fit <- arima(tsbl$Weekly_Sales, order=c(3,0,2))\n",
    "summary(arima_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a706a0",
   "metadata": {},
   "source": [
    "Forecasting with Auto.Arima and Arima modelling. \n",
    "\n",
    "**1. Forecasting from Auto - Arima Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto - Arima Modelling\n",
    "plot(forecast(model1, h=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6d381",
   "metadata": {},
   "source": [
    "**2. Forecasting from Arima Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arima Modelling\n",
    "plot(forecast(arima_fit, h=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1e3c1",
   "metadata": {},
   "source": [
    "**From the above observations we can say that arima model predictions are better than auto.arima model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116163de",
   "metadata": {},
   "source": [
    "### To calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset <- subset(df_20, Date <= as.POSIXct(\"2012-08-03\"))\n",
    "tail(df_subset)\n",
    "\n",
    "df_subset_1 <- subset(df_20, Date > as.POSIXct(\"2012-08-03\"))\n",
    "\n",
    "paste(\"The length of the time series is\", nrow(df_subset), \"weeks and it ranges from\", min(df_subset$Date), \"to\", max(df_subset$Date))\n",
    "\n",
    "paste(\"The length of the time series is\", nrow(df_subset_1), \"weeks and it ranges from\", min(df_subset_1$Date), \"to\", max(df_subset_1$Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df10db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_1 <- ts(df_subset[, 2:ncol(df_subset)], start = c(2010, 6),  frequency = 365.25 / 7)\n",
    "str(ts_1)\n",
    "tsbl_1 <- as_tsibble(ts_1, pivot_longer = FALSE)\n",
    "str(tsbl_1)\n",
    "\n",
    "\n",
    "ts_2 <- ts(df_subset_1[, 2:ncol(df_subset_1)], start =  c(2012, 8),  frequency = 365.25 / 7)\n",
    "str(ts_2)\n",
    "tsbl_2 <- as_tsibble(ts_2, pivot_longer = FALSE)\n",
    "str(tsbl_2)\n",
    "\n",
    "tsbl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed86a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arima\n",
    "arima_fit_1 <- arima(tsbl_1$Weekly_Sales, order=c(3,0,2))\n",
    "summary(arima_fit_1)\n",
    "forecast_1 <- forecast(arima_fit_1, h=12)\n",
    "plot(forecast_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(forecast_1, tsbl_2$Weekly_Sales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
